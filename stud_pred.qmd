---
title: "Student Performance Predictor"
author: "Shifa Panjwani"
editor: visual
format:
  html:
    embed-resources: true
---

### Problem Statement

In the field of education, understanding the factors influencing student performance is critical for improving academic outcomes. This project aims to develop a predictive model to estimate students' Math scores using the **Student Performance Prediction** dataset. The dataset contains various demographic and academic features, including **gender**, **race/ethnicity**, **parental education level**, **lunch type**, **test preparation course completion**, as well as **reading and writing scores**.

The primary objective is to analyze how these factors contribute to Math performance and create an accurate machine learning model that can predict Math scores. By identifying the most significant predictors, the study will provide actionable insights for educators, policymakers, and academic institutions to implement targeted interventions and improve student outcomes.

**Key Goals:**

-   Develop a regression-based predictive model to estimate Math scores

-   Perform EDA to identify patterns and correlations

-   Evaluate linear and KNN model performances using appropriate metrics (e.g., RMSE, R-squared)

-   Identify the best model

This project will leverage various machine learning algorithms and evaluate their effectiveness to select the best-performing model. The results will offer valuable insights into the factors influencing Math achievement and suggest strategies for academic support.

### Loading Libraries

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(ISLR2)
library(dplyr)
library(readr)
```

### Loading Dataset

```{r}
#| message: false
#| warning: false
data <- read_csv('/Users/shifapanjwani/Desktop/GitHub/mlproject/notebook/data/stud.csv')
head(data)
```

## Data Cleaning

### Missing Values

```{r}
sum(is.na(data))
```

### Outliers

```{r}
data |>
  select(math_score, reading_score, writing_score) |>
  gather(key = "variable", value = "value") |>
  ggplot(aes(x = variable, y = value)) +
  geom_boxplot() +
  labs(title = "Boxplot of Math, Reading, and Writing Scores to Identify Outliers")


remove_outliers <- function(data, col) {
  Q1 <- quantile(data[[col]], 0.25)
  Q3 <- quantile(data[[col]], 0.75)
  IQR <- Q3 - Q1
  data %>% filter(data[[col]] >= (Q1 - 1.5 * IQR) & data[[col]] <= (Q3 + 1.5 * IQR))
}

# Remove outliers from math, reading, and writing scores
data_clean <- data |>
  remove_outliers("math_score") |>
  remove_outliers("reading_score") |>
  remove_outliers("writing_score")

# Check the dimensions before and after outlier removal
cat("Original data: ", nrow(data), "rows\n")
cat("Cleaned data: ", nrow(data_clean), "rows\n")

data_clean |>
  select(math_score, reading_score, writing_score) |>
  gather(key = "variable", value = "value") |>
  ggplot(aes(x = variable, y = value)) +
  geom_boxplot() +
  labs(title = "Boxplot of Math, Reading, and Writing Scores to Identify Outliers")

```

## Exploratory Data Analysis

### Summary

```{r}
summary(data_clean)
```

### Near-Zero Variance

```{r}
data_clean |> count(gender)
data_clean |> count(race_ethnicity)
data_clean |> count(parental_level_of_education)
data_clean |> count(lunch)
data_clean |> count(test_preparation_course)
```

### Math Score vs. Gender

```{r}
ggplot(data_clean, aes(x = gender, y = math_score, fill = gender)) +
  geom_boxplot() +
  labs(title = "Gender vs Math Score")
```

### Math Score vs. Test Preparation Course 

```{r}
ggplot(data_clean, aes(x = test_preparation_course, y = math_score, fill = test_preparation_course)) +
  geom_boxplot() +
  labs(title = "Test Preparation Course vs Math Score")
```

### Correlation Matrix

```{r}
correlation_matrix <- cor(data_clean |>
                            select_if(is.numeric))
print(correlation_matrix)
```

## Data Preprocessing

### Categorical Columns to Factors

```{r}
data_clean <- data_clean |>
  mutate(across(where(is.character), as.factor))
```

### Data Splitting

```{r}
set.seed(427)
data_split <- initial_split(data_clean, prop = 0.7)
train_data <- training(data_split)
test_data <- testing(data_split)
```

### Linear Regression Recipes

This section creates 3 different data preprocessing pipelines using the 'recipes' package from tidymodels to prepare data for linear regression models. Each recipe applies various imputation, encoding and normalization techniques to handle missing values, categorical data, and scaling.

#### Recipe 1: Mean Imputation + Dummy Encoding + Normalization

```{r}
recipe_lm1 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_mean(all_numeric_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_lincomb(all_predictors()) |>
  step_normalize(all_numeric_predictors())
```

#### Recipe 2: Median Imputation + Zero-Variance Removal + Ordinal Encoding

```{r}
recipe_lm2 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_median(all_numeric_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_integer(all_nominal_predictors()) |>
  step_lincomb(all_predictors()) |>
  step_normalize(all_numeric_predictors())
```

#### Recipe 3: KNN Imputation + Lumping Rare Categories + Normalization

```{r}
recipe_lm3 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_knn(all_numeric_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_other(all_nominal_predictors(), threshold = 0.05) |>
  step_dummy(all_nominal_predictors()) |>
  step_lincomb(all_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors())
```

#### Preparation of Recipes

```{r}
prep_lm1 <- prep(recipe_lm1)
prep_lm2 <- prep(recipe_lm2)
prep_lm3 <- prep(recipe_lm3)
```

### KNN Recipes

#### Recipe 1: Mean Imputation + One-Hot Encoding + Zero-Variance Removal +Normalization

```{r}
recipe_knn1 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_mean(all_numeric_predictors()) |>  
  step_unknown(all_nominal_predictors()) |>  
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  
  step_zv(all_predictors()) |> 
  step_normalize(all_numeric_predictors())
```

#### Recipe 2: Median Imputation + Lumping Rare Categories + Zero-Variance Removal + Normalization

```{r}
recipe_knn2 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_median(all_numeric_predictors()) |>  
  step_other(all_nominal_predictors(), threshold = 0.02) |>  
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  
  step_zv(all_predictors()) |> 
  step_normalize(all_numeric_predictors())
```

#### Recipe 3: KNN Imputation + Zero-Variance Removal + Normalization

```{r}
recipe_knn3 <- recipe(math_score ~ ., data = train_data) |>
  step_impute_knn(all_numeric_predictors()) |>  
  step_unknown(all_nominal_predictors()) |>  
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  
  step_zv(all_predictors()) |>  
  step_normalize(all_numeric_predictors())
```

#### Preparation of Recipes

```{r}
prep_knn1 <- prep(recipe_knn1)
prep_knn2 <- prep(recipe_knn2)
prep_knn3 <- prep(recipe_knn3)
```

## Model Definition

### Linear Regression

```{r}
lm_model <- linear_reg() |>  
  set_engine("lm")


```

### KNN Models

```{r}
knn_model3 <- nearest_neighbor(neighbors = 3) |> 
  set_engine("kknn") |> 
  set_mode("regression")
knn_model5 <- nearest_neighbor(neighbors = 5) |> 
  set_engine("kknn") |> 
  set_mode("regression")
knn_model10 <- nearest_neighbor(neighbors = 10) |> 
  set_engine("kknn") |> 
  set_mode("regression")


```

## Workflow Creation

### Linear Regression Workflow Set

```{r}
lm_workflows <- workflow_set(
  preproc = list(
    "lm_recipe1" = recipe_lm1,
    "lm_recipe2" = recipe_lm2,
    "lm_recipe3" = recipe_lm3
  ),
  models = list(
    "lm_model" = lm_model
  ),
  cross = TRUE
)
```

### KNN Workflow Set

```{r}
knn_workflows <- workflow_set(
  preproc = list(
    "knn_recipe1" = recipe_knn1,
    "knn_recipe2" = recipe_knn2,
    "knn_recipe3" = recipe_knn3
  ),
  models = list(
    "knn_3" = knn_model3,
    "knn_5" = knn_model5,
    "knn_10" = knn_model10
  ),
  cross = TRUE
)
```

### Combining All Workflows

```{r}
all_workflows <- lm_workflows |> 
  bind_rows(knn_workflows)
```

## Cross-Validation & Model Evaluation

```{r}
set.seed(427)

cv_splits <- vfold_cv(train_data, v = 5, repeats = 5)
metrics <- metric_set(rmse, rsq)

cv_results <- workflow_map(
  all_workflows,
  resamples = cv_splits,
  metrics = metrics
)

cv_metrics <- cv_results |> collect_metrics()
```

## Visualization of Model Performance

### RMSE Plot

```{r}
ggplot(cv_metrics |> filter(.metric == "rmse"), aes(x = wflow_id, y = mean, fill = model)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "RMSE Comparison of Workflows",
    x = "Workflow ID",
    y = "Mean RMSE"
  ) +
  theme_minimal()
```

### R-Squared Plot

```{r}
ggplot(cv_metrics |> filter(.metric == "rsq"), aes(x = wflow_id, y = mean, fill = model)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "R-Squared Comparison of Workflows",
    x = "Workflow ID",
    y = "Mean R-Squared"
  ) +
  theme_minimal()
```

## Model Selection, Fitting & Evaluation

```{r}
# Extract and Fit Best Model
best_workflow <- all_workflows |>
  extract_workflow("lm_recipe1_lm_model") 

# Re-fit the model
set.seed(427)
data_split <- initial_split(data_clean, prop = 0.7)
final_fit <- last_fit(best_workflow, split = data_split, metrics = metric_set(rmse, rsq))

# Evaluate on Test Set
test_metrics <- collect_metrics(final_fit)
test_metrics

```
